# -*- coding: utf-8 -*-
"""Copy of V3.1-B.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hdfr--qYrsRZGAtBB0thFBvWLqMo_som

## Import the libraries
Importing necessary libraries
"""

import tensorflow as tf
import json
import nltk
from sklearn.model_selection import train_test_split

"""## Import the dataset

Import the training file, load it into your workspace and put the sentences and labels into lists.
"""

!sudo apt install jq
!rm data.json data.jsonl data.jsonl.gz
!wget https://huggingface.co/datasets/dair-ai/emotion/resolve/main/data/data.jsonl.gz
!gunzip data.jsonl.gz
!jq --slurp . < data.jsonl > data.json
!rm data.jsonl

# Load the JSON file
with open("data.json", 'r') as f:
  datastore = json.load(f)

  # Initialize the lists
  sentences = []
  labels = []

  # Collect sentences and labels into the lists
  for item in datastore:
      sentences.append(item['text'])
      labels.append(item['label'])

vocab_size = 100000  # Maximum vocab size.
max_len = 32  # Sequence length to pad the outputs to.
embedding_dim = 32

training_sentences, testing_sentences, training_labels, testing_labels = train_test_split(sentences, labels, test_size=0.2, random_state=42)

"""## Model

Establish the text vectorization
"""

vectorize_layer = tf.keras.layers.TextVectorization(
 max_tokens=vocab_size,
 standardize='lower',
 output_mode='int',
 output_sequence_length=max_len)

vectorize_layer.adapt(training_sentences)

"""Remove stop words"""

nltk.download('stopwords')

stop_words = stopwords.words('english')
vocabs = vectorize_layer.get_vocabulary()

for stop_word in stop_words:
  if stop_word in vectorize_layer.get_vocabulary():
    vocabs.remove(stop_word)

vectorize_layer.set_vocabulary(vocabs)

"""Build the Model"""

# Create the model that uses the vectorize text layer
model = tf.keras.models.Sequential([
    tf.keras.Input(shape=(1,), dtype=tf.string),
    vectorize_layer,
    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_len),
    tf.keras.layers.SpatialDropout1D(0.5),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),
    tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu'),
    tf.keras.layers.GlobalMaxPooling1D(),
    tf.keras.layers.Dense(16, kernel_regularizer=tf.keras.regularizers.L2(0.001), activation='relu'),
    tf.keras.layers.Dense(6, activation='softmax')
])

# Summary of Model
model.summary()

model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

num_epochs = 30
early_stopping = tf.keras.callbacks.EarlyStopping(patience=3)

# Train the model
history = model.fit(training_sentences, training_labels, epochs=num_epochs, validation_data=(testing_sentences, testing_labels), callbacks=[early_stopping], verbose=2)

"""## Testing preview"""

import numpy as np

emotion_labels = ['Sadness', 'Joy', 'Love', 'Anger', 'Fear', 'Surprise']  # Emotion labels based on your dataset

user_inputs = testing_sentences[:10]
result_detail = 0

# Predict emotions for user inputs
predictions = model.predict(user_inputs)

# Print the predicted emotions and their percentages for each user input
for i, text in enumerate(user_inputs):
    print(f"Sentence: {text}")
    if i < len(predictions):
      if result_detail == 1:
        prediction = predictions[i]
        predicted_percentages = [percentage * 100 for percentage in prediction]
        emotion_percentages = {
            emotion: percentage
            for emotion, percentage in zip(emotion_labels, predicted_percentages)
        }
        print("Emotion Percentages:")
        for emotion, percentage in emotion_percentages.items():
            print(f"{emotion}: {percentage:.2f}%")
      if result_detail == 0:
        print(f"Predicted Emotion: {[emotion_labels[prediction.argmax()] for prediction in predictions][i]}")
    else:
        print("Unable to predict emotion for this sentence.")
    print()

"""## Convert into TensorFlow Lite
Converting model into TFLite then export it
"""

# Convert the TensorFlow model to TensorFlow Lite format
converter = tf.lite.TFLiteConverter.from_keras_model(model)

converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.experimental_new_converter=True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
tf.lite.OpsSet.SELECT_TF_OPS]

tflite_model = converter.convert()

# Save the TensorFlow Lite model to a file
tflite_model_path = "./tflite_model_v3.2.tflite"
with open(tflite_model_path, 'wb') as f:
    f.write(tflite_model)